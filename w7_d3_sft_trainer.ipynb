{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUa2qF3UF8JgEyDhnybdup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mightyoctopus/amazon-pricer-model-open-source-fine-tuned-models/blob/main/w7_d3_sft_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training with SFT Trainer"
      ],
      "metadata": {
        "id": "-L0os1dE4He7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sQSc2sSfTc2"
      },
      "outputs": [],
      "source": [
        "# pip installs\n",
        "\n",
        "!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q --upgrade requests==2.32.3 bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 datasets==3.2.0 peft==0.14.0 trl==0.14.0 matplotlib wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, set_seed, BitsAndBytesConfig\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import wandb\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PmOw8duF4Rnu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils.import_utils import BASE_FILE_REQUIREMENTS\n",
        "### Constants\n",
        "\n",
        "BASE_MODEL = \"meta-llama/Meta-Llama-3.1-8B\"\n",
        "PROJECT_NAME = \"product-pricer\"\n",
        "HF_USER = \"MightyOctopus\"\n",
        "\n",
        "### Data\n",
        "\n",
        "# https://huggingface.co/datasets/MightyOctopus/amazon-pricer-dataset-v2-0\n",
        "DATASET_NAME = f\"{HF_USER}/amazon-pricer-dataset-v2-0\"\n",
        "MAX_SEQUENCE_LENGTH = 182\n",
        "\n",
        "### Run name for saving the model in the hub:\n",
        "RUN_NAME = f\"{datetime.now():%Y-$m-%d_H%.%M.%S}\"\n",
        "PROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\n",
        "HUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\"\n",
        "\n",
        "\n",
        "### Hyperparameters for QLoRA\n",
        "LORA_R = 32\n",
        "LORA_ALPHA = 64\n",
        "TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
        "LORA_DROPOUT = 0.1\n",
        "QUANT_4_BIT = True\n",
        "\n",
        "\n",
        "### Hyperparameters for Training\n",
        "EPOCHS = 1 # more than 1 might be overkill\n",
        "BATCH_SIZE = 4 # Great for T4. If A100, this can be up to 16\n",
        "GRADIENT_ACCUMULATION_STEPS = 8 # Better generalization and stable learning\n",
        "LEARNING_RATE = 1e-4\n",
        "LR_SCHEDULER_TYPE = \"cosine\"\n",
        "WARMUP_RATIO = 0.03\n",
        "OPTIMIZER = \"paged_adamw_32bit\"\n",
        "\n",
        "\n",
        "### Admin Config:\n",
        "STEPS = 50\n",
        "SAVE_STEPS = 2000\n",
        "LOG_TO_WANDB = True\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "sw6oRb1F5HIF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HUB_MODEL_NAME"
      ],
      "metadata": {
        "id": "it-JjEXM86t_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}